{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "# Standard Utility Libraries\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# TensorFlow/Keras Deep Learning Libraries\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.models import Sequential, save_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Configuration ---\n",
        "# Set the desired image size (will be cropped/resized to this)\n",
        "SIZE = 128\n",
        "# Configuration for the Kaggle Dataset\n",
        "KAGGLE_DATASET_ID = 'alxmamaev/flowers-recognition'\n",
        "DESTINATION_DIR = './Image_CLF_Datasets/'\n",
        "FLOWERS_DIR = os.path.join(DESTINATION_DIR, 'flowers/')\n",
        "# --- End Configuration ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # create config dir\n",
        "# mkdir -p ~/.config/kaggle\n",
        "\n",
        "# # move kaggle.json (example: you uploaded it to the workspace root)\n",
        "# mv /workspaces/flower-detection/kaggle.json ~/.config/kaggle/\n",
        "\n",
        "# # set secure perms and correct ownership to current user\n",
        "# chmod 600 ~/.config/kaggle/kaggle.json\n",
        "# sudo chown $(id -un):$(id -gn) ~/.config/kaggle -R\n",
        "\n",
        "# # verify\n",
        "# ls -l ~/.config/kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ...existing code...\n",
        "# Ensure Kaggle credentials are present before importing kaggle\n",
        "kaggle_json = os.path.expanduser(\"~/.config/kaggle/kaggle.json\")\n",
        "if os.path.exists(kaggle_json):\n",
        "    os.chmod(kaggle_json, 0o600)\n",
        "    import kaggle\n",
        "    print(\"Kaggle API configured via ~/.config/kaggle/kaggle.json\")\n",
        "elif os.environ.get(\"KAGGLE_USERNAME\") and os.environ.get(\"KAGGLE_KEY\"):\n",
        "    import kaggle\n",
        "    print(\"Kaggle API configured via environment variables\")\n",
        "else:\n",
        "    raise SystemExit(\n",
        "        \"Kaggle credentials not found. Place kaggle.json in ~/.config/kaggle/ or set KAGGLE_USERNAME/KAGGLE_KEY.\"\n",
        "    )\n",
        "# ...existing code..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Data Fetching and Preparation üöÄ\n",
        "\n",
        "# Ensure Kaggle API is available and configured\n",
        "try:\n",
        "    import kaggle\n",
        "    print(\"Kaggle API successfully imported.\")\n",
        "except ImportError:\n",
        "    print(\"Kaggle library not found. Installing now...\")\n",
        "    subprocess.run(['pip', 'install', 'kaggle'], check=True)\n",
        "    import kaggle # Re-import after installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_and_extract_kaggle_dataset(dataset_id, dest_dir):\n",
        "    \"\"\"Downloads and extracts the Kaggle dataset.\"\"\"\n",
        "    \n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "    \n",
        "    # Use the Kaggle CLI to download the dataset\n",
        "    print(f\"Downloading dataset: {dataset_id}...\")\n",
        "    try:\n",
        "        # Downloads the zip file to the destination directory\n",
        "        subprocess.run(['kaggle', 'datasets', 'download', '-d', dataset_id, '-p', dest_dir], check=True)\n",
        "        print(\"Download complete.\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"\\nERROR: Kaggle download failed. Please check credentials and connection.\")\n",
        "        print(\"Ensure the 'kaggle.json' file is correctly placed in ~/.kaggle/ for API authentication.\")\n",
        "        return False\n",
        "        \n",
        "    # Find and extract the downloaded zip file\n",
        "    zip_files = [f for f in os.listdir(dest_dir) if f.endswith('.zip')]\n",
        "    if not zip_files:\n",
        "        print(\"Error: Downloaded zip file not found.\")\n",
        "        return False\n",
        "\n",
        "    zip_path = os.path.join(dest_dir, zip_files[0])\n",
        "    \n",
        "    print(f\"Extracting {zip_files[0]}...\")\n",
        "    shutil.unpack_archive(zip_path, dest_dir)\n",
        "    os.remove(zip_path) # Clean up the zip file\n",
        "    print(f\"Data ready at: {FLOWERS_DIR}\")\n",
        "    \n",
        "    # Renaming the extracted folder if necessary (specific to this dataset)\n",
        "    extracted_folder_name = 'flowers'\n",
        "    if extracted_folder_name not in os.listdir(dest_dir):\n",
        "        # A common issue is the folder name being \"flowers-recognition\" or similar\n",
        "        print(\"Attempting to locate flower images...\")\n",
        "        \n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if data is already present before downloading\n",
        "if not os.path.isdir(FLOWERS_DIR) or not os.listdir(FLOWERS_DIR):\n",
        "    print(\"Dataset not found locally. Starting download and extraction...\")\n",
        "    success = download_and_extract_kaggle_dataset(KAGGLE_DATASET_ID, DESTINATION_DIR)\n",
        "    if not success:\n",
        "        raise SystemExit(\"Dataset setup failed. Cannot proceed with training.\")\n",
        "else:\n",
        "    print(f\"Dataset already found at {FLOWERS_DIR}. Skipping download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Data Loading and Preprocessing ---\n",
        "data = []\n",
        "label = []\n",
        "\n",
        "# Assuming the 'flowers' folder contains subfolders, where each subfolder name is a class label.\n",
        "for folder in os.listdir(FLOWERS_DIR):\n",
        "    folder_path = os.path.join(FLOWERS_DIR, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith(\"jpg\"):\n",
        "                label.append(folder)\n",
        "                # Read, convert (BGR to RGB), and resize image\n",
        "                img = cv2.imread(os.path.join(folder_path, file))\n",
        "                if img is not None:\n",
        "                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    im = cv2.resize(img_rgb, (SIZE, SIZE))\n",
        "                    data.append(im)\n",
        "\n",
        "# Convert data into numerical values\n",
        "X = np.array(data)\n",
        "label_arr = np.array(label)\n",
        "\n",
        "# Use label encoder and one-hot encode the data\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(label_arr)\n",
        "\n",
        "# Get the list of class names in the order they were encoded\n",
        "categories = encoder.classes_\n",
        "NUM_CLASSES = len(categories)\n",
        "print(f\"\\nDetected {NUM_CLASSES} classes: {categories}\")\n",
        "\n",
        "# One-hot encoding\n",
        "y = to_categorical(y_encoded, NUM_CLASSES)\n",
        "\n",
        "# Normalize the image data (scaling pixel values to [0, 1])\n",
        "X = X / 255.0\n",
        "\n",
        "# Split the dataset into 70% training and 30% testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "print(f\"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Build Convolutional Neural Network (CNN) Architecture üèóÔ∏è\n",
        "\n",
        "model = Sequential(name='Flower_Classifier_CNN')\n",
        "\n",
        "# First Convolutional Block\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu', input_shape=(SIZE, SIZE, 3), name='Conv_1_64'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), name='Pool_1'))\n",
        "\n",
        "# Second Convolutional Block (Triple Conv Layers)\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='Same', activation='relu', name='Conv_2_128_a'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='Same', activation='relu', name='Conv_2_128_b'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='Same', activation='relu', name='Conv_2_128_c'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), name='Pool_2'))\n",
        "\n",
        "# Fully Connected Layers (Classifier)\n",
        "model.add(Flatten(name='Flatten_Layer'))\n",
        "model.add(Dense(128, activation='relu', name='Dense_128'))\n",
        "model.add(Dense(64, activation='relu', name='Dense_64'))\n",
        "model.add(Dropout(rate=0.25, name='Dropout_0_25'))\n",
        "# Output Layer\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax', name='Output_5_Classes'))\n",
        "\n",
        "print(\"\\n--- Model Summary ---\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate model plot (requires pydot and graphviz)\n",
        "try:\n",
        "    plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n",
        "    print(\"\\nModel architecture saved to model_architecture.png\")\n",
        "except ImportError:\n",
        "    print(\"\\nWarning: pydot or graphviz not installed. Skipping model plot generation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Data Augmentation and Model Training ‚öôÔ∏è\n",
        "\n",
        "# Image Data Augmentation settings\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.20,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 64\n",
        "\n",
        "# Use Model.fit() which replaces the deprecated Model.fit_generator\n",
        "print(\"\\n--- Model Training Started ---\")\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=2\n",
        ")\n",
        "print(\"--- Model Training Finished ---\")\n",
        "\n",
        "# Save the trained model artifact\n",
        "save_model(model, 'flower_classifier_model.h5')\n",
        "print(\"\\nTrained model saved as 'flower_classifier_model.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Evaluation and Visualization üìä\n",
        "\n",
        "# --- A. Plot Training History ---\n",
        "def plot_history(history):\n",
        "    \"\"\"Plots the training and validation loss and accuracy history.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax1.set_title('Model Accuracy')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.legend(loc='lower right')\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    ax2.plot(history.history['loss'], label='Train Loss')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax2.set_title('Model Loss')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.legend(loc='upper right')\n",
        "    ax2.grid(True)\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- B. Visualize Predictions on Test Set ---\n",
        "\n",
        "# Run prediction once for efficiency\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Display 36 random test images with predictions\n",
        "fig, ax = plt.subplots(6, 6, figsize=(25, 25))\n",
        "fig.suptitle(\"CNN Flower Classification Results\", fontsize=24)\n",
        "\n",
        "for i in range(6):\n",
        "    for j in range(6):\n",
        "        k = int(np.random.random_sample() * len(X_test))\n",
        "        \n",
        "        true_label = categories[y_true_classes[k]]\n",
        "        pred_label = categories[y_pred_classes[k]]\n",
        "\n",
        "        is_correct = (true_label == pred_label)\n",
        "        color = 'green' if is_correct else 'red'\n",
        "\n",
        "        ax[i, j].set_title(f\"TRUE: {true_label}\", color=color)\n",
        "        ax[i, j].set_xlabel(f\"PREDICTED: {pred_label}\", color=color)\n",
        "        ax[i, j].imshow(X_test[k]) \n",
        "        ax[i, j].axis('off')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n",
        "\n",
        "# --- C. Plot Confusion Matrix ---\n",
        "\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=categories, yticklabels=categories)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2TrJJy5SO12"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#Encoding and Split data into Train/Test Sets\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Tensorflow Keras CNN Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad,Adadelta,RMSprop\n",
        "\n",
        "#Plot Images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "folder_dir = '/content/drive/MyDrive/Image_CLF_Datasets/flowers'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeES559_SX63"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "label = []\n",
        "\n",
        "#crop the image to 128 x 128\n",
        "SIZE = 128\n",
        "\n",
        "for folder in os.listdir(folder_dir):\n",
        "    for file in os.listdir(os.path.join(folder_dir, folder)):\n",
        "        if file.endswith(\"jpg\"):\n",
        "            label.append(folder)\n",
        "            img = cv2.imread(os.path.join(folder_dir, folder, file))\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            im = cv2.resize(img_rgb, (SIZE,SIZE))\n",
        "            data.append(im)\n",
        "        else:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmIO5ZRVUFHM"
      },
      "outputs": [],
      "source": [
        "# Convert data into numerical values\n",
        "data_arr = np.array(data)\n",
        "label_arr = np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q18M-p05UShR"
      },
      "outputs": [],
      "source": [
        "# print(data_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exgFh5qoUmPo"
      },
      "outputs": [],
      "source": [
        "# print(label_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpYVgxvQUqzF",
        "outputId": "d4c21a1d-5c30-41fa-a883-c09479722315"
      },
      "outputs": [],
      "source": [
        "# Use label encoder and normalize the data\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(label_arr)\n",
        "print(y)\n",
        "y = to_categorical(y,5)\n",
        "print(y)\n",
        "X = data_arr/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx_cqlnvU5YV"
      },
      "outputs": [],
      "source": [
        "#split the dataset into 80% training and 20% testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lomGICGJU5bv"
      },
      "outputs": [],
      "source": [
        "# Build Neura Network for flower classification:\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu', input_shape = (SIZE, SIZE,3) ))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"Same\", activation = 'relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"Same\", activation = 'relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"Same\", activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8ZcghgLb5Vz",
        "outputId": "925058c9-58e1-4b86-d3ea-721f72deeeb2"
      },
      "outputs": [],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CSmV08tZcBx"
      },
      "outputs": [],
      "source": [
        "# We need to create more training images to prevent overfitting before compiling\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 20,\n",
        "    zoom_range = 0.20,\n",
        "    width_shift_range = 0.3,\n",
        "    height_shift_range = 0.3,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLHC3sEvaNXv",
        "outputId": "871a22b9-35fd-4398-b92a-63bce2af7818"
      },
      "outputs": [],
      "source": [
        "#compile the model\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "batch_size = 32\n",
        "epochs = 64\n",
        "history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs,\n",
        "                              validation_data = (X_test,y_test),\n",
        "                              verbose = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WxeFDdQaNZS",
        "outputId": "57456055-f2b7-454c-8b86-0e95ae57872a"
      },
      "outputs": [],
      "source": [
        "# let model identify the flower\n",
        "\n",
        "categories = np.sort(os.listdir(folder_dir))\n",
        "fig, ax = plt.subplots(6,6, figsize=(25,40))\n",
        "\n",
        "for i in range(6):\n",
        "    for j in range(6):\n",
        "        k = int(np.random.random_sample() * len(X_test))\n",
        "        if(categories[np.argmax(y_test[k])] == categories[np.argmax(model.predict(X_test)[k])]):\n",
        "            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='green')\n",
        "            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])],color='green')\n",
        "            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE,SIZE,3), cmap='gray')\n",
        "        else:\n",
        "            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='red')\n",
        "            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])],color='red')\n",
        "            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE,SIZE,3), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnJ_57moaNcp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
